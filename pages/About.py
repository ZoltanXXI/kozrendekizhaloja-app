import os
import re
import unicodedata
from html import unescape
from pathlib import Path
from collections import defaultdict

import pandas as pd
import networkx as nx
from scipy.stats import spearmanr
import streamlit as st

try:
    from utils.fasting import FASTING_RECIPE_TITLES, FASTING_KEYWORDS, classify_fasting_text
except Exception:
    try:
        from utils.fasting import FASTING_RECIPE_TITLES
    except Exception:
        FASTING_RECIPE_TITLES = []
    FASTING_KEYWORDS = ['b√∂jt', 'post', 'fast', 'fasta', 'luszt', 'lent'] 
    classify_fasting_text = None

def strip_icon_ligatures(s):
    if not isinstance(s, str):
        return ""
    s = unicodedata.normalize('NFKC', s)
    s = re.sub(r'<[^>]+>', '', s)
    s = re.sub(r'[_\-\s]+', ' ', s).strip()
    return s

def normalize_label(s):
    if not isinstance(s, str):
        return ''
    s = strip_icon_ligatures(s).lower()
    s = re.sub(r'\s+', ' ', s).strip()
    return s

def resolve_historical_csv_path():
    script_dir = os.path.dirname(__file__)
    candidates = [
        os.path.join(script_dir, 'data', 'HistoricalRecipe_export.csv'),
        os.path.join(os.getcwd(), 'data', 'HistoricalRecipe_export.csv'),
        os.path.join(os.path.abspath(os.path.join(script_dir, '..')), 'data', 'HistoricalRecipe_export.csv'),
        'data/HistoricalRecipe_export.csv',
        'HistoricalRecipe_export.csv'
    ]
    for p in candidates:
        if os.path.exists(p):
            return p
    return None

def resolve_tripartit_path():
    script_dir = os.path.dirname(__file__)
    candidates = [
        os.path.join(script_dir, 'data', 'Recept_halo__molekula_tripartit.csv'),
        os.path.join(os.getcwd(), 'data', 'Recept_halo__molekula_tripartit.csv'),
        'data/Recept_halo__molekula_tripartit.csv',
        'Recept_halo__molekula_tripartit.csv'
    ]
    for p in candidates:
        if os.path.exists(p):
            return p
    return None

def resolve_edges_path():
    script_dir = os.path.dirname(__file__)
    candidates = [
        os.path.join(script_dir, 'data', 'recept_halo_edges.csv'),
        os.path.join(os.getcwd(), 'data', 'recept_halo_edges.csv'),
        'data/recept_halo_edges.csv',
        'recept_halo_edges.csv'
    ]
    for p in candidates:
        if os.path.exists(p):
            return p
    return None

st.set_page_config(page_title="A PROJEKTR≈êL", page_icon="üìú", layout="wide")

st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Cinzel:wght@400;700;900&display=swap');
[data-testid="stSidebar"] > div:first-child {
    background-color: #5c1a1a !important;
    font-family: 'Cinzel', serif !important;
    color: #ffffff !important;
}
[data-testid="stSidebar"] button,
[data-testid="stSidebar"] .st-expander,
[data-testid="stSidebar"] span,
[data-testid="stSidebar"] div[data-testid$="-label"] {
    font-family: 'Cinzel', serif !important;
    color: #ffffff !important;
}
[data-testid="stSidebar"] span[data-testid="stIconMaterial"],
.span[data-testid="stIconMaterial"] {
    display: none !important;
}
[data-testid="stKeyboardShortcutButton"],
button[aria-label="Show keyboard shortcuts"],
button[aria-label="Show keyboard navigation"],
[data-testid^="stTooltip"] {
    display: none !important;
}
.list-card {
    background: #fffaf2;
    border: 1px solid #e6d2a3;
    padding: 12px;
    border-radius: 8px;
    margin-bottom: 12px;
}
.list-title {
    font-weight: 700;
    color: #2c1810;
    font-size: 1.05rem;
    margin-bottom: 8px;
}
.list-item {
    margin: 6px 0;
    line-height: 1.4;
}
.metric-card {
    text-align: center;
    padding: 1.5rem;
    background: #fffbf0;
    border-radius: 8px;
    border: 2px solid #d4af37;
}
</style>
""", unsafe_allow_html=True)

st.markdown("""
<div style="
    display: block;
    width: fit-content;
    margin: 0 auto;
    padding: 0.5rem 2rem;
    background: linear-gradient(to right, #5c070d, #840a13);
    border-radius: 8px;
    text-align: center;
">
    <h1 style="font-family: Cinzel, serif; color: #ffffff; margin: 0;">A PROJEKTR≈êL</h1>
</div>
<div style="
    width: 100px;
    height: 4px;
    background: linear-gradient(to right, #d4af37, #f0d98d, #d4af37);
    margin: 1.5rem auto 3rem auto;
    border-radius: 2px;
"></div>
""", unsafe_allow_html=True)

st.markdown("""
<div class="reader-quote">
    <span class="first-letter">E</span>z az √©n k√∂nyvecsk√©m nem siet az udvarokban val√≥ nagy konyh√°khoz,
    ahol a szak√°csok csak magokt√≥l is j√≥√≠z≈± √©tkeket tudnak f≈ëzni; hanem csak legink√°bb
    a becs√ºletes k√∂zrendeknek, akik gyakorta szak√°cs n√©lk√ºl sz≈±k√∂lk√∂dnek, akar szolg√°lni‚Ä¶
    <br/><br/>
    Az√©rt j√°mbor Olvas√≥, ha kedved szerint vagyon ez a k√∂nyvecske, vegyed j√≥ n√©ven,
    √©s l√©gy j√≥ eg√©szs√©gben!
    <div class="signature">‚Äî Az Olvas√≥hoz, Kolozsv√°r, 1698</div>
</div>
""", unsafe_allow_html=True)

st.markdown("""
<div class="body-text">
    <p>
        <span class="first-letter-main">A</span> K√∂zrendek √çzh√°l√≥ja projekt c√©lja,
        hogy modern technol√≥gia seg√≠ts√©g√©vel eleven√≠tse fel a XVII. sz√°zadi magyar gasztron√≥mia
        elfeledett vil√°g√°t. A projekt alapj√°t a h√≠res "Szak√°csmesters√©gnek k√∂nyvecsk√©je" k√©pezi,
        amely 1698-ban jelent meg Kolozsv√°ron, √©s az egyik legkor√°bbi r√°nk maradt magyar nyelv≈±
        nyomtatott szak√°csk√∂nyv.
    </p>
</div>
""", unsafe_allow_html=True)

st.markdown("""
<h3 class="section-title">
    üìñ A Forr√°sm≈±
</h3>
""", unsafe_allow_html=True)

st.markdown("""
<div class="body-text">
    <p>
        A <a href="https://mek.oszk.hu/08300/08343/08343.htm" target="_blank" rel="noopener noreferrer">
        Szak√°csmesters√©gnek k√∂nyvecsk√©je</a> receptjei nem pontos mennyis√©geket, hanem ar√°nyokat √©s
        elj√°r√°sokat r√∂gz√≠tenek. A k√∂nyv kifejezetten a "becs√ºletes k√∂zrendeknek" k√©sz√ºlt, akik gyakorta
        szak√°cs n√©lk√ºl sz≈±k√∂lk√∂dtek. Ez a <em>network science</em> (h√°l√≥zatkutat√°s) szempontj√°b√≥l
        k√ºl√∂n√∂sen izgalmas, hiszen az alapanyagok kapcsol√≥d√°sai rajzolj√°k ki a kor √≠zl√©svil√°g√°nak t√©rk√©p√©t.
    </p>
</div>
""", unsafe_allow_html=True)

st.markdown("---")

tripartit_path = resolve_tripartit_path()
edges_path = resolve_edges_path()
hist_path = resolve_historical_csv_path()

if not (tripartit_path and edges_path and hist_path):
    st.warning("A h√°l√≥zati / t√∂rt√©neti CSV f√°jlok nem tal√°lhat√≥k. Ellen≈ërizd, hogy a projekt `data/` mapp√°j√°ban vannak-e:\n- Recept_halo__molekula_tripartit.csv\n- recept_halo_edges.csv\n- HistoricalRecipe_export.csv")
else:
    tripartit = pd.read_csv(tripartit_path, delimiter=';', encoding='utf-8', on_bad_lines='skip')
    edges = pd.read_csv(edges_path, delimiter=',', encoding='utf-8', on_bad_lines='skip')
    historical = pd.read_csv(hist_path, encoding='utf-8', on_bad_lines='skip')

    label_col = next((c for c in tripartit.columns if c.lower() in ('label','name','title')), tripartit.columns[0])
    tripartit['Label'] = tripartit[label_col].astype(str).apply(strip_icon_ligatures)
    type_col = next((c for c in tripartit.columns if 'type' in c.lower() or 'category' in c.lower()), None)
    tripartit['node_type'] = tripartit[type_col].astype(str).fillna('Egy√©b') if type_col is not None else 'Egy√©b'
    tripartit['norm'] = tripartit['Label'].apply(normalize_label)
    node_norm_map = {r['norm']: r for _, r in tripartit.iterrows()}

    if 'norm_source' in edges.columns and 'norm_target' in edges.columns:
        srcs = edges['norm_source'].astype(str).tolist()
        tgts = edges['norm_target'].astype(str).tolist()
    else:
        srcs = edges.iloc[:,0].astype(str).tolist()
        tgts = edges.iloc[:,1].astype(str).tolist()

    def resolve_norm(val):
        if not isinstance(val, str):
            return ''
        return normalize_label(val)

    srcs = [resolve_norm(s) for s in srcs]
    tgts = [resolve_norm(t) for t in tgts]
    edge_list = [(s, t) for s, t in zip(srcs, tgts) if s and t]

    G = nx.Graph()
    for _, r in tripartit.iterrows():
        G.add_node(r['norm'], label=r['Label'], node_type=r['node_type'])
    G.add_edges_from(edge_list)

    ingredient_nodes = [n for n, d in G.nodes(data=True) if 'ingredient' in str(d.get('node_type', '')).lower() or 'alapanyag' in str(d.get('node_type', '')).lower()]

    deg = dict(G.degree())
    pr = nx.pagerank(G, alpha=0.85) if G.number_of_nodes() > 0 else {}
    bet = nx.betweenness_centrality(G) if G.number_of_nodes() > 0 else {}
    eig = {}
    try:
        eig = nx.eigenvector_centrality_numpy(G) if G.number_of_nodes() > 0 else {}
    except Exception:
        eig = {}

    def top_for(metric_dict, nodes, topn=10):
        return sorted(((n, metric_dict.get(n, 0)) for n in nodes), key=lambda x: x[1], reverse=True)[:topn]

    top_deg = top_for(deg, ingredient_nodes, 10)
    top_pr = top_for(pr, ingredient_nodes, 10)
    top_bet = top_for(bet, ingredient_nodes, 10)
    top_eig = top_for(eig, ingredient_nodes, 10)

    def readable(norm):
        return G.nodes[norm].get('label') if norm in G.nodes else norm

    molecules = [n for n, d in G.nodes(data=True) if 'molecule' in str(d.get('node_type', '')).lower() or 'molekula' in str(d.get('node_type', '')).lower()]
    recipes = [n for n, d in G.nodes(data=True) if 'dish' in str(d.get('node_type', '')).lower() or 'recept' in str(d.get('node_type', '')).lower() or 'recipe' in str(d.get('node_type', '')).lower()]

    ing_to_mols = {ing: set() for ing in ingredient_nodes}
    ing_to_recipes = {ing: set() for ing in ingredient_nodes}
    for ing in ingredient_nodes:
        for mol in molecules:
            if G.has_edge(ing, mol):
                ing_to_mols[ing].add(mol)
        for rec in recipes:
            if G.has_edge(ing, rec):
                ing_to_recipes[ing].add(rec)

    pair_shared_mols = []
    pair_coocc = []
    ing_list = ingredient_nodes
    for i in range(len(ing_list)):
        for j in range(i + 1, len(ing_list)):
            a = ing_list[i]
            b = ing_list[j]
            shared = len(ing_to_mols[a] & ing_to_mols[b])
            coocc = len(ing_to_recipes[a] & ing_to_recipes[b])
            if shared > 0 or coocc > 0:
                pair_shared_mols.append(shared)
                pair_coocc.append(coocc)

    corr = None
    pval = None
    if len(pair_shared_mols) >= 10 and sum(pair_shared_mols) > 0:
        corr, pval = spearmanr(pair_shared_mols, pair_coocc)

    fasting_set = {normalize_label(t) for t in FASTING_RECIPE_TITLES}
    titles_norm = historical['title'].astype(str).apply(normalize_label)
    text_fields = []
    for c in ('text', 'instructions', 'description', 'ingredients', 'body'):
        if c in historical.columns:
            text_fields.append(c)
    fasting_flags = []
    for idx, row in historical.iterrows():
        title = normalize_label(str(row.get('title', '')))
        combined_text = title
        for c in text_fields:
            combined_text = combined_text + ' ' + normalize_label(str(row.get(c, '')))
        is_fasting = False
        if title in fasting_set:
            is_fasting = True
        else:
            for kw in (FASTING_KEYWORDS if FASTING_KEYWORDS else []):
                if kw in combined_text:
                    is_fasting = True
                    break
        if classify_fasting_text is not None:
            try:
                clf_res = classify_fasting_text(title + ' ' + combined_text)
                if isinstance(clf_res, bool):
                    is_fasting = is_fasting or clf_res
                elif isinstance(clf_res, (int, float)) and clf_res >= 0.5:
                    is_fasting = True
            except Exception:
                pass
        fasting_flags.append(is_fasting)
    fast_count = sum(1 for f in fasting_flags if f)
    fast_pct = round(fast_count / len(historical) * 100, 1) if len(historical) > 0 else 0.0

    st.markdown("### Kutat√°si eredm√©nyek (adatok alapj√°n)")
    st.markdown("**1) Mely alapanyagok voltak a legk√∂zpontibbak?**")

    deg_col, pr_col, bet_col = st.columns(3)

    with deg_col:
        st.markdown('<div class="list-card"><div class="list-title">Top 10 ‚Äî Degree (kapcsolatok sz√°ma)</div>', unsafe_allow_html=True)
        for i, (n, v) in enumerate(top_deg, start=1):
            st.markdown(f'<div class="list-item">{i}. <strong>{readable(n)}</strong> ‚Äî {int(v)}</div>', unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)

    with pr_col:
        st.markdown('<div class="list-card"><div class="list-title">Top 10 ‚Äî PageRank (h√°l√≥zati befoly√°s)</div>', unsafe_allow_html=True)
        for i, (n, v) in enumerate(top_pr, start=1):
            st.markdown(f'<div class="list-item">{i}. <strong>{readable(n)}</strong> ‚Äî {v:.6f}</div>', unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)

    with bet_col:
        st.markdown('<div class="list-card"><div class="list-title">Top 10 ‚Äî Betweenness (hidak)</div>', unsafe_allow_html=True)
        for i, (n, v) in enumerate(top_bet, start=1):
            st.markdown(f'<div class="list-item">{i}. <strong>{readable(n)}</strong> ‚Äî {v:.6f}</div>', unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)

    st.markdown("---")
    st.markdown("**2) Van-e m√©rhet≈ë kapcsolat az √≠z-aroma molekul√°k √©s a t√∂rt√©neti p√°ros√≠t√°sok k√∂z√∂tt?**")
    if corr is None:
        st.markdown("Nem volt el√©g p√°ros adat a megb√≠zhat√≥ Spearman korrel√°ci√≥ sz√°m√≠t√°shoz (kev√©s k√∂z√∂s molekula / p√°ros).")
    else:
        st.markdown(f"Spearman rho = **{corr:.3f}**, p = **{pval:.3g}**")
        if pval < 0.05:
            st.markdown("√ârt√©kel√©s: statisztikailag szignifik√°ns korrel√°ci√≥ ‚Äî a k√∂z√∂s molekul√°k sz√°ma r√©szben magyar√°zza az egy√ºtt el≈ëfordul√°s gyakoris√°g√°t.")
        else:
            st.markdown("√ârt√©kel√©s: nincs szignifik√°ns korrel√°ci√≥ ‚Äî a molekul√°ris hasonl√≥s√°g √∂nmag√°ban nem magyar√°zza a t√∂rt√©neti p√°ros√≠t√°sokat.")

    st.markdown("---")

    metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)

    with metric_col1:
        st.markdown(f'<div class="metric-card"><div style="font-size: 2.5rem; font-weight: bold; color: #8b5a2b;">{len(historical)}</div><div style="color:#4a3728; font-size:1rem; margin-top:0.5rem;">T√∂rt√©neti Recept</div></div>', unsafe_allow_html=True)

    with metric_col2:
        st.markdown(f'<div class="metric-card"><div style="font-size: 2.5rem; font-weight: bold; color: #8b5a2b;">{G.number_of_nodes()}</div><div style="color:#4a3728; font-size:1rem; margin-top:0.5rem;">Node (H√°l√≥zat)</div></div>', unsafe_allow_html=True)

    with metric_col3:
        avg_words = round(historical['title'].astype(str).apply(lambda t: len(t.split())).mean() if 'title' in historical.columns else 0, 1)
        st.markdown(f'<div class="metric-card"><div style="font-size: 2.5rem; font-weight: bold; color: #8b5a2b;">{avg_words}</div><div style="color:#4a3728; font-size:1rem; margin-top:0.5rem;">√Åtlag Sz√≥sz√°m (c√≠m)</div></div>', unsafe_allow_html=True)

    with metric_col4:
        st.markdown(f'<div class="metric-card"><div style="font-size: 2.5rem; font-weight: bold; color: #8b5a2b;">{fast_pct}%</div><div style="color:#4a3728; font-size:1rem; margin-top:0.5rem;">B√∂jti Receptek (detekt√°lva)</div></div>', unsafe_allow_html=True)

    st.markdown("---")
    st.markdown("**4) Mennyire k√∂zel√≠ti meg az AI a t√∂rt√©neti receptek st√≠lus√°t √©s szerkezet√©t?**")
    st.markdown("Az AI-alap√∫ gener√°l√°s `novelty` / `similarity` metrik√°val m√©rhet≈ë: SequenceMatcher/levenshtein alap√∫ hasonl√≥s√°g a t√∂rt√©neti corpus-szal, majd `novelty = 1 - max_similarity` minden gener√°ci√≥ra.")
    st.markdown("Aj√°nlott k√ºsz√∂b: ha similarity > 0.6 ‚Üí √∫j gener√°l√°s vagy er≈ësebb prompt grounding.")

st.markdown("---")

st.markdown("""
<div class="highlight-box" style="text-align: center; font-size: 1.3rem;">
    ‚ÄûA f≈ëz√©s az az a fajta m≈±v√©szet, amely a t√∂rt√©nelmi term√©keket k√©pes pillanatok alatt √©lvezett√© var√°zsolni.‚Äù
                                                                                                    ‚Äì Guy Savoy
</div>
""", unsafe_allow_html=True)

st.markdown("""
<div style="text-align: center; margin-top: 4rem; padding: 2rem; background: linear-gradient(to bottom, #fffbf0, #fff9e6); border-radius: 8px;">
    <div style="font-size: 1.5rem; font-weight: bold; color: #2c1810; font-family: Georgia, serif; margin-bottom: 1rem;">
        K√∂zrendek √çzh√°l√≥ja
    </div>
    <div style="color: #5c4033; font-size: 1rem; margin-bottom: 0.5rem;">
        H√°l√≥zatelemz√©s + T√∂rt√©neti Forr√°sok + AI Gener√°l√°s
    </div>
    <div style="color: #8b5a2b; font-size: 0.9rem;">
        ¬© 2025 | Built with Streamlit, NetworkX, Plotly, Anthropic's Claude, GrokAI & OpenAI GPTs
    </div>
</div>
""", unsafe_allow_html=True)
